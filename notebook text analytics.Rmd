---
title: "R Notebook"
output:
  word_document: default
  html_notebook: default
  pdf_document: default
toc: yes
---

```{r loading libs and data, include=FALSE}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(tokenizers)
library(tidytext)
library(SnowballC)
library(tm)
library(stringi)
library(ggrepel)
library(wordcloud)
library(syuzhet)
library(qdap)



# wd Ertiza
# wd Shane
wd <- "C:/Users/mingh/Documents/Text-analytics"
# wd Najla <- 
setwd(wd)


reviews_df <- read.csv("Womens Clothing E-Commerce Reviews.csv")
```


```{r merge title and review body}
reviews_df$text_full <- paste(reviews_df$Title, reviews_df$Review.Text, sep = " ")
```


```{r Remove unnecessary punctuation}
reviews_df$Review <- as.character(reviews_df$text_full)  %>% 
  tolower() %>% 
  {gsub(":( |-|o)*\\("," SADSMILE ", .)} %>%       # Find :( or :-( or : ( or :o(
  {gsub(":( |-|o)*\\)"," HAPPYSMILE ", .)} %>%     # Find :) or :-) or : ) or :o)
  {gsub("(\"| |\\$)-+\\.-+"," NUMBER", .)} %>%     # Find numbers
  {gsub("([0-9]+:)*[0-9]+ *am"," TIME_AM", .)} %>%         # Find time AM
  {gsub("([0-9]+:)*[0-9]+ *pm"," TIME_PM", .)} %>%         # Find time PM
  {gsub("-+:-+","TIME", .)} %>%                    # Find general time
  {gsub("\\$ ?[0-9]*[\\.,]*[0-9]+"," DOLLARVALUE ", .)} %>%           # Find Dollar values
  {gsub("[0-9]*[\\.,]*[0-9]+"," NUMBER ", .)} %>%           # Find remaining numbers
  {gsub("-"," ", .)} %>%                           # Remove all -
  {gsub("&"," and ", .)} %>%                       # Find general time
  {gsub("\"+"," ", .)} %>%                         # Remove all "
  {gsub("\\|+"," ", .)} %>%                        # Remove all |
  {gsub("_+"," ", .)} %>%                          # Remove all _
  {gsub(";+"," ", .)} %>%                          # Remove excess ;
  {gsub(" +"," ", .)} %>%                          # Remove excess spaces
  {gsub("\\.+","\\.", .)}                          # Remove excess .
```


```{r Remove stop words}
#cut text into words by splitting on spaces and punctuation
review_words <- reviews_df %>% unnest_tokens(word,Review,to_lower=TRUE) 
print("number of words")
nrow(review_words)

#Count the number of times each word occurs
counts <- review_words %>%count(word, sort=TRUE) # sort = TRUE for sorting in descending order of n. 
# For questions about a function type ?fun in the console. For example ?count
print("number of unique words")
nrow(counts)

review_words_nostop <- review_words %>% 
                        anti_join(stop_words)
counts <- review_words_nostop %>%
            count(word, sort=TRUE)

print("number of words without stop words")
sum(counts$n)
```


```{r plot after removing stop words}
counts %>% 
  mutate(word = reorder(word,n)) %>% 
  top_n(30, word) %>%
  ggplot(aes(word,n)) +  
  geom_col() + 
  labs(x = NULL, y = "Number of occurences") + 
  coord_flip() + 
  theme(text = element_text(size = 17)) + 
  ggtitle("Word Frequency Histogram")
```


```{r stemming}
# Creating the full review from the cleaned+stemmedwords

 for (j in 1:nrow(reviews_df)) {
  stemmed_Review<-  anti_join((reviews_df[j,] %>% unnest_tokens(word,Review, drop=FALSE,to_lower=TRUE) ),stop_words)
   
  stemmed_Review<-(wordStem(stemmed_Review[,"word"], language = "porter"))
 
  reviews_df[j,"Review"]<-paste((stemmed_Review),collapse = " ")
   
 }
```


```{r new clean data plot}
#cut text into words by splitting on spaces and punctuation
review_words_clean <- reviews_df %>% unnest_tokens(word,Review,to_lower=TRUE) 

#Count the number of times each word occurs
counts_clean <- review_words_clean %>%count(word, sort=TRUE) # sort = TRUE for sorting in descending order of n. 
# For questions about a function type ?fun in the console. For example ?count

counts_clean %>% 
  mutate(word = reorder(word,n)) %>% 
  top_n(30, word) %>%
  ggplot(aes(word,n)) +  
  geom_col() + 
  labs(x = NULL, y = "Number of occurences") + 
  coord_flip() + 
  theme(text = element_text(size = 17)) + 
  ggtitle("Word Frequency Histogram")


```




```{r}
head(reviews_df$Review, n=5)
```
```{r}
# normal wordcloud
wordcloud(words = counts_clean$word , freq = counts_clean$n, min.freq = 1000,
          max.words=70, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))





```


```{r}


```



